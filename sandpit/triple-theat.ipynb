{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ef80255",
   "metadata": {},
   "source": [
    "# `triple-threat` proof of concept\n",
    "Proof of concept for a triple-fitting, cherry-picking, tree-building algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f71f1501",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "from cogent3 import load_aligned_seqs, PhyloNode\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88a792d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-02 14:15:42.661246: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "tfd = tfp.distributions\n",
    "tfb = tfp.bijectors\n",
    "\n",
    "tf.executing_eagerly()  # need to check whether this is the default for tensorflow > 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bccbca69",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-02 14:15:44.238394: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1\n",
      "2021-09-02 14:15:44.279961: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-09-02 14:15:44.280270: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA GeForce RTX 2080 with Max-Q Design computeCapability: 7.5\n",
      "coreClock: 1.095GHz coreCount: 46 deviceMemorySize: 7.79GiB deviceMemoryBandwidth: 357.69GiB/s\n",
      "2021-09-02 14:15:44.280292: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
      "2021-09-02 14:15:44.281452: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
      "2021-09-02 14:15:44.282516: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\n",
      "2021-09-02 14:15:44.282706: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\n",
      "2021-09-02 14:15:44.283936: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\n",
      "2021-09-02 14:15:44.284638: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\n",
      "2021-09-02 14:15:44.287248: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n",
      "2021-09-02 14:15:44.287348: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-09-02 14:15:44.287725: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-09-02 14:15:44.288019: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\n"
     ]
    }
   ],
   "source": [
    "# this stops tensorflow from snaffling all of the GPU\n",
    "# thanks https://stackoverflow.com/questions/34199233/how-to-prevent-tensorflow-from-allocating-the-totality-of-a-gpu-memory\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "  tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a19d43",
   "metadata": {},
   "source": [
    "## Data import\n",
    "Reads an alignments and creates a list of 4 x 4 x 4 joint frequencies tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "81060425",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_triples(aln, nuc_order='ACGT', codon_position=3, verbose=False):\n",
    "    aln = aln[codon_position - 1::3].no_degenerates()\n",
    "    if verbose:\n",
    "        print(f'Got {len(aln)} positions')\n",
    "    assert len(aln) <= np.iinfo(np.int32).max\n",
    "    triples = []\n",
    "    nuc_map = {n:i for i, n in enumerate(nuc_order)}\n",
    "    for triple in combinations(range(aln.num_seqs), 3):\n",
    "        F = np.zeros([4, 4, 4], dtype=np.int32)\n",
    "        subaln = aln.get_sub_alignment(seqs=triple)\n",
    "        for a, b, c in subaln:\n",
    "            F[nuc_map[a], nuc_map[b], nuc_map[c]] += 1\n",
    "        triples.append([tuple(subaln.names), F])\n",
    "    return triples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "754e30f2",
   "metadata": {},
   "source": [
    "## Triple fitting functions\n",
    "Collection of functions for concurrent fitting of many triples on CPUs and GPUs. Model is rooted, continuous-time, and strand-symmetric.\n",
    "\n",
    "Also some functions for using Akaike-ish weights to find the pair that is most probably a cherry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b5ddd765",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function()\n",
    "def transform_P_matrix(params):\n",
    "    params = tf.exp(params)\n",
    "    Q0 = tf.concat([[-tf.reduce_sum(params[0])], params[0]],\n",
    "                   axis=0)\n",
    "    Q1 = tf.concat([[params[1,0]], [-tf.reduce_sum(params[1])], params[1,1:]],\n",
    "                   axis=0)\n",
    "    Q = tf.concat([[Q0], [Q1], [Q1[::-1]], [Q0[::-1]]], axis=0)\n",
    "    return tf.linalg.expm(Q)\n",
    "\n",
    "@tf.function()\n",
    "def transform(params):\n",
    "    pi = tfb.SoftmaxCentered()(params[0])\n",
    "    Pa = transform_P_matrix(params[1:3])\n",
    "    Pm = transform_P_matrix(params[3:5])\n",
    "    Pb = transform_P_matrix(params[5:7])\n",
    "    Pc = transform_P_matrix(params[7:9])\n",
    "    return pi, Pa, Pm, Pb, Pc\n",
    "    \n",
    "@tf.function()\n",
    "def _loss(params_data):\n",
    "    params, data = params_data\n",
    "    pi, Pa, Pm, Pb, Pc = transform(params)\n",
    "    J = tf.einsum('i,ij,ik,ku,kv', pi, Pa, Pm, Pb, Pc)\n",
    "    loss = tf.reduce_sum(tf.keras.losses.KLDivergence()(J, data))\n",
    "    return loss\n",
    "    \n",
    "@tf.function()\n",
    "def loss(params, data):\n",
    "    # could do better managing the variance in the shared matrix case here\n",
    "    return tf.reduce_sum(tf.vectorized_map(_loss, (params, data)))\n",
    "\n",
    "@tf.function()\n",
    "def training_step(parameters, data, optimizer, unscrambler):\n",
    "    with tf.GradientTape() as tape:\n",
    "        unscrambled = _unscramble(parameters, unscrambler)\n",
    "        loss_value = loss(unscrambled, data)\n",
    "    gradients = tape.gradient(loss_value, parameters)\n",
    "    return loss_value, gradients\n",
    "\n",
    "# thanks https://github.com/mlgxmez/thelongrun_notebooks/blob/master/MLE_tutorial.ipynb\n",
    "def mle_fit(data, loss, parameters, optimizer, unscrambler, steps=500, verbose=False):\n",
    "    for i in range(steps):\n",
    "        loss_value, gradients = training_step(parameters, data, optimizer, unscrambler)\n",
    "        optimizer.apply_gradients([(gradients, parameters)])\n",
    "        \n",
    "        if i % 100 == 0:\n",
    "            if verbose:\n",
    "                iter_info = f\"Step: {optimizer.iterations.numpy()}, initial loss: {loss_value.numpy()}\"\n",
    "                print(iter_info)\n",
    "\n",
    "def check_cherry(ls, N):\n",
    "    ls = N*ls\n",
    "    delta = ls - ls.min()\n",
    "    weights = np.exp(-delta)\n",
    "    return weights/weights.sum()\n",
    "\n",
    "@tf.function()\n",
    "def _unscramble(parameters, unscramble):\n",
    "    unscrambled = []\n",
    "    for t1 in unscramble:\n",
    "        unscrambled.append(tf.stack([parameters[i] for i in t1]))\n",
    "    return tf.stack(unscrambled)\n",
    "\n",
    "def fit_triples(triples, learning_rate=0.01, cherries_share_matrices=True, steps=3000, verbose=False):\n",
    "    K = 0\n",
    "    cherry_loc = {}\n",
    "    unscrambler = []\n",
    "    data = []\n",
    "    for names, F in triples:\n",
    "        J = (F/F.sum()).astype(np.float32)\n",
    "        for ix in [[0, 1, 2], [1, 2, 0], [2, 0, 1]]:\n",
    "            t1 = list(range(K, K+5)) # for pi and two Ps\n",
    "            K += 5\n",
    "            cherry = [names[ix[1]], names[ix[2]]]\n",
    "            frozen_cherry = frozenset(cherry)\n",
    "            if not cherries_share_matrices or frozen_cherry not in cherry_loc:\n",
    "                new_loc = {cherry[0]: [K,K+1], cherry[1]: [K+2,K+3]}\n",
    "                K += 4\n",
    "                cherry_loc[frozen_cherry] = new_loc\n",
    "            t1.extend(cherry_loc[frozen_cherry][cherry[0]]) # for the first cherry\n",
    "            t1.extend(cherry_loc[frozen_cherry][cherry[1]]) # for the second cherry\n",
    "            unscrambler.append(t1)\n",
    "        \n",
    "            data.append(J.transpose(ix))\n",
    "\n",
    "    normal_initializer = tf.random_normal_initializer()\n",
    "    parameters = tf.Variable(normal_initializer(shape=[K, 3], dtype=tf.float32), name='params')\n",
    "    data = tf.stack(data)\n",
    "\n",
    "    optimizer = tf.optimizers.Adam(learning_rate=learning_rate)\n",
    "    mle_fit(data, loss, parameters, optimizer, unscrambler, steps=steps, verbose=verbose)\n",
    "    \n",
    "    parameters = _unscramble(parameters, unscrambler)\n",
    "    losses = tf.vectorized_map(_loss, (parameters, data)).numpy()\n",
    "    losses = [losses[i:i+3] for i in range(0, len(losses), 3)]\n",
    "    fits = [[p.numpy() for p in transform(params)] for params in parameters]\n",
    "    fits = [fits[i:i+3] for i in range(0, len(fits), 3)]\n",
    "    return losses, fits\n",
    "\n",
    "def pick_cherry(root_probs):\n",
    "    cherry_llik = Counter()\n",
    "    for probs in root_probs:\n",
    "        names = frozenset(probs.keys())\n",
    "        for name in names:\n",
    "            cherry_llik[names - {name}] += np.log(probs[name])\n",
    "    return cherry_llik.most_common()\n",
    "\n",
    "def get_cherries(triples, losses, verbose=False):\n",
    "    root_probs = []\n",
    "    for losses, (names, F) in zip(losses, triples):\n",
    "        probs = check_cherry(losses, F.sum())\n",
    "        root_probs.append(dict(zip(names, probs)))\n",
    "    \n",
    "    cherry_llik = pick_cherry(root_probs)\n",
    "    if verbose:\n",
    "        for (n1, n2), ll in cherry_llik:\n",
    "            print(f'{n1}, {n2}: {ll}')\n",
    "    \n",
    "    return list(cherry_llik[0][0])\n",
    "\n",
    "def get_Ps(cherry_names, triples, fits):\n",
    "    Ps = {}\n",
    "    ixes = [[0, 1, 2], [1, 2, 0], [2, 0, 1]]\n",
    "    for (names, _), triple_fit in zip(triples, fits):\n",
    "        if set(cherry_names) < set(names):\n",
    "            for name, ix, fit in zip(names, ixes, triple_fit):\n",
    "                if name not in cherry_names:\n",
    "                    if names[ix[1]] == cherry_names[0]:\n",
    "                        return fit[-2], fit[-1]\n",
    "                    return fit[-1], fit[-2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be342abd",
   "metadata": {},
   "source": [
    "## Merge-step functions\n",
    "Functions that merge pairs of of triples to create merged triples. Concurrently creates joint probability matrices for all merged triples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e3d710d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_cherries(triples, cherries, learning_rate=0.01, steps=3000, verbose=False):\n",
    "    keepers = []\n",
    "    to_be_merged = defaultdict(lambda: [None, None])\n",
    "    cherry_names, cherry_Ps = cherries\n",
    "    for names, F in triples:\n",
    "        num_uncommon = len(set(names) - set(cherry_names))\n",
    "        if num_uncommon == 3:\n",
    "            keepers.append((names, F))\n",
    "        elif num_uncommon == 2:\n",
    "            uncommon = frozenset(names) - frozenset(cherry_names)\n",
    "            name = (set(names) - uncommon).pop()\n",
    "            new_names = sorted(uncommon) + [name]\n",
    "            ix = [names.index(n) for n in new_names]\n",
    "            J = F.transpose(ix).astype(np.float32)\n",
    "            J /= J.sum()\n",
    "            N = F.sum()  # make no mistake, this is a kludge\n",
    "            to_be_merged[tuple(new_names[:2])][name == cherry_names[1]] = J\n",
    "\n",
    "    @tf.function()\n",
    "    def transform(params):\n",
    "        return tf.reshape(tfb.SoftmaxCentered()(params), (4, 4, 4))\n",
    "    \n",
    "    @tf.function()\n",
    "    def _loss(params_data):\n",
    "        params, data = params_data\n",
    "        J = transform(params)\n",
    "        twoJs = [J @ cherry_Ps[0], J @ cherry_Ps[1]]\n",
    "        # could do better managing the variance here\n",
    "        loss = tf.reduce_sum(tf.keras.losses.KLDivergence()(J, data))\n",
    "        return loss\n",
    "    \n",
    "    @tf.function()\n",
    "    def loss(params, data):\n",
    "        return tf.reduce_sum(tf.vectorized_map(_loss, (params, data)))\n",
    "\n",
    "    @tf.function()\n",
    "    def training_step(parameters, data, optimizer):\n",
    "        with tf.GradientTape() as tape:\n",
    "            loss_value = loss(parameters, data)\n",
    "        gradients = tape.gradient(loss_value, parameters)\n",
    "        return loss_value, gradients\n",
    "    \n",
    "    def mle_fit(data, loss, parameters, optimizer, steps, verbose):\n",
    "        for i in range(steps):\n",
    "            loss_value, gradients = training_step(parameters, data, optimizer)\n",
    "            optimizer.apply_gradients([(gradients, parameters)])\n",
    "\n",
    "            if i % 100 == 0:\n",
    "                if verbose:\n",
    "                    iter_info = f\"Step: {optimizer.iterations.numpy()}, initial loss: {loss_value.numpy()}\"\n",
    "                    print(iter_info)\n",
    "    \n",
    "    normal_initializer = tf.random_normal_initializer()\n",
    "    K = len(to_be_merged)\n",
    "    parameters = tf.Variable(normal_initializer(shape=[K, 63], dtype=tf.float32), name='params')\n",
    "    data = tf.stack(list(to_be_merged.values()))\n",
    "    \n",
    "    optimizer = tf.optimizers.Adam(learning_rate=learning_rate)\n",
    "    mle_fit(data, loss, parameters, optimizer, steps=steps, verbose=verbose)\n",
    "    \n",
    "    for names, params in zip(to_be_merged, parameters.numpy()):\n",
    "        keepers.append((list(names) + ['-'.join(cherry_names)], N*transform(params).numpy()))\n",
    "        \n",
    "    return keepers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7078c4",
   "metadata": {},
   "source": [
    "## Tree building algorithm\n",
    "Functions for using cherry-picking to build trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f13b5ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_tree(forest, cherries):\n",
    "    new_node = PhyloNode('-'.join(cherries[0]))\n",
    "    for name, P in zip(*cherries):\n",
    "        child = forest[name]\n",
    "        child.P = P\n",
    "        new_node.append(child)\n",
    "        del forest[name]\n",
    "    forest[new_node.name] = new_node\n",
    "\n",
    "def triple_threat(triples, cherries_share_matrices=False, learning_rate=0.01, steps=3000, verbose=False):\n",
    "    triples = list(triples)\n",
    "    forest = {n: PhyloNode(n) for names, _ in triples for n in names}\n",
    "    while True:\n",
    "        if verbose:\n",
    "            print('Looking for cherries')\n",
    "        losses, fits = fit_triples(triples, cherries_share_matrices=cherries_share_matrices,\n",
    "                                   learning_rate=learning_rate, steps=steps, verbose=verbose)\n",
    "        cherry_names = get_cherries(triples, losses, verbose=verbose)\n",
    "        if verbose:\n",
    "            print('Fitting cherries')\n",
    "        if not cherries_share_matrices:\n",
    "            triples_for_cherry = [t for t in triples if set(cherry_names) < set(t[0])]\n",
    "            _, fits = fit_triples(triples_for_cherry, cherries_share_matrices=True,\n",
    "                                  learning_rate=learning_rate, steps=steps, verbose=verbose)\n",
    "            cherry_Ps = get_Ps(cherry_names, triples_for_cherry, fits)\n",
    "        else:\n",
    "            cherry_Ps = get_Ps(cherry_names, triples, fits)\n",
    "        cherries = cherry_names, cherry_Ps\n",
    "        update_tree(forest, cherries)\n",
    "        if verbose:\n",
    "            for tree in forest.values():\n",
    "                print(tree)\n",
    "        if len(triples) == 1:\n",
    "            break\n",
    "        if verbose:\n",
    "            print('Merging cherries')\n",
    "        triples = merge_cherries(triples, cherries, learning_rate=learning_rate, steps=steps, verbose=verbose)\n",
    "    tree = PhyloNode('-'.join(forest.keys()))\n",
    "    tree.pi = fits[0][0][0]\n",
    "    for name, child in forest.items():\n",
    "        if name in triples[0][0]:\n",
    "            fit = fits[0][triples[0][0].index(name)]\n",
    "            Pa = fit[1]\n",
    "            Pm = fit[2]\n",
    "    for name, child in forest.items():\n",
    "        child.P = Pa if name in triples[0][0] else Pm\n",
    "        tree.append(child)\n",
    "    return tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b80287a2",
   "metadata": {},
   "source": [
    "# Some examples\n",
    "## Example 1\n",
    "Fit a rooted phylogeny of 5 mammals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640da74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "aln = load_aligned_seqs('/home/ben/Data/pentads/ENSG00000197102.fa.gz', moltype=\"dna\")\n",
    "# aln = load_aligned_seqs('/home/ben/Data/pentads/ENSG00000131018.fa.gz', moltype=\"dna\")\n",
    "# aln = load_aligned_seqs('/home/ben/Data/pentads/ENSG00000179869.fa.gz', moltype=\"dna\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a7b20afb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".c3align td { border: none !important; text-align: left !important; }\n",
       ".c3align tr:not(.num_row) td span {margin: 0 2px;}\n",
       ".c3align tr:nth-child(even) {background: #f7f7f7;}\n",
       ".c3align .num_row {background-color:rgba(161, 195, 209, 0.5) !important; border-top: solid 1px black; }\n",
       ".c3align .label { font-size: 12pt ; text-align: right !important; color: black !important; padding: 0 4px; display: table-cell !important; font-weight: normal !important; }\n",
       ".c3align .T_dna{font-family: \"Lucida Console\",monospace !important; font-size: 12pt !important; color: blue; }\n",
       ".c3align .C_dna{font-family: \"Lucida Console\",monospace !important; font-size: 12pt !important; color: black; }\n",
       ".c3align .A_dna{font-family: \"Lucida Console\",monospace !important; font-size: 12pt !important; color: #FF0102; }\n",
       ".c3align .G_dna{font-family: \"Lucida Console\",monospace !important; font-size: 12pt !important; color: green; }\n",
       ".c3align .terminal_ambig_dna{font-family: \"Lucida Console\",monospace !important; font-size: 12pt !important; color: gray; }\n",
       ".c3align .ambig_dna{font-family: \"Lucida Console\",monospace !important; font-size: 12pt !important; color: gray; }\n",
       "</style>\n",
       "<div class=\"c3align\">\n",
       "<table>\n",
       "<tr class=\"num_row\"><td></td><td><b>0</b></td></tr>\n",
       "<tr><td class=\"label\">Platypus</td><td><span class=\"A_dna\">A</span><span class=\"T_dna\">T</span><span class=\"G_dna\">G</span><span class=\"T_dna\">T</span><span class=\"C_dna\">C</span><span class=\"G_dna\">G</span><span class=\"G_dna\">G</span><span class=\"A_dna\">A</span><span class=\"G_dna\">G</span><span class=\"ambig_dna\">-</span><span class=\"ambig_dna\">-</span><span class=\"ambig_dna\">-</span><span class=\"ambig_dna\">-</span><span class=\"ambig_dna\">-</span><span class=\"ambig_dna\">-</span><span class=\"G_dna\">G</span><span class=\"G_dna\">G</span><span class=\"C_dna\">C</span><span class=\"G_dna\">G</span><span class=\"G_dna\">G</span><span class=\"C_dna\">C</span><span class=\"G_dna\">G</span><span class=\"G_dna\">G</span><span class=\"C_dna\">C</span><span class=\"G_dna\">G</span><span class=\"G_dna\">G</span><span class=\"C_dna\">C</span><span class=\"G_dna\">G</span><span class=\"A_dna\">A</span><span class=\"G_dna\">G</span><span class=\"G_dna\">G</span><span class=\"A_dna\">A</span><span class=\"C_dna\">C</span><span class=\"G_dna\">G</span><span class=\"G_dna\">G</span><span class=\"C_dna\">C</span><span class=\"T_dna\">T</span><span class=\"C_dna\">C</span><span class=\"G_dna\">G</span><span class=\"T_dna\">T</span><span class=\"C_dna\">C</span><span class=\"G_dna\">G</span><span class=\"G_dna\">G</span><span class=\"G_dna\">G</span><span class=\"C_dna\">C</span><span class=\"C_dna\">C</span><span class=\"T_dna\">T</span><span class=\"G_dna\">G</span><span class=\"G_dna\">G</span><span class=\"A_dna\">A</span><span class=\"G_dna\">G</span><span class=\"G_dna\">G</span><span class=\"T_dna\">T</span><span class=\"G_dna\">G</span><span class=\"T_dna\">T</span><span class=\"C_dna\">C</span><span class=\"G_dna\">G</span><span class=\"G_dna\">G</span><span class=\"C_dna\">C</span><span class=\"G_dna\">G</span></td></tr>\n",
       "<tr><td class=\"label\">Dog</td><td><span class=\"A_dna\">.</span><span class=\"T_dna\">.</span><span class=\"G_dna\">.</span><span class=\"T_dna\">.</span><span class=\"C_dna\">.</span><span class=\"G_dna\">.</span><span class=\"G_dna\">.</span><span class=\"A_dna\">.</span><span class=\"G_dna\">.</span><span class=\"C_dna\">C</span><span class=\"C_dna\">C</span><span class=\"G_dna\">G</span><span class=\"G_dna\">G</span><span class=\"G_dna\">G</span><span class=\"C_dna\">C</span><span class=\"G_dna\">.</span><span class=\"G_dna\">.</span><span class=\"C_dna\">.</span><span class=\"G_dna\">.</span><span class=\"G_dna\">.</span><span class=\"C_dna\">.</span><span class=\"G_dna\">.</span><span class=\"G_dna\">.</span><span class=\"C_dna\">.</span><span class=\"G_dna\">.</span><span class=\"G_dna\">.</span><span class=\"C_dna\">.</span><span class=\"G_dna\">.</span><span class=\"A_dna\">.</span><span class=\"G_dna\">.</span><span class=\"G_dna\">.</span><span class=\"A_dna\">.</span><span class=\"C_dna\">.</span><span class=\"G_dna\">.</span><span class=\"G_dna\">.</span><span class=\"C_dna\">.</span><span class=\"T_dna\">.</span><span class=\"C_dna\">.</span><span class=\"G_dna\">.</span><span class=\"G_dna\">G</span><span class=\"C_dna\">.</span><span class=\"G_dna\">.</span><span class=\"G_dna\">.</span><span class=\"G_dna\">.</span><span class=\"C_dna\">.</span><span class=\"C_dna\">.</span><span class=\"T_dna\">.</span><span class=\"G_dna\">.</span><span class=\"G_dna\">.</span><span class=\"A_dna\">.</span><span class=\"G_dna\">.</span><span class=\"G_dna\">.</span><span class=\"T_dna\">.</span><span class=\"G_dna\">.</span><span class=\"T_dna\">.</span><span class=\"C_dna\">.</span><span class=\"G_dna\">.</span><span class=\"G_dna\">.</span><span class=\"C_dna\">.</span><span class=\"C_dna\">C</span></td></tr>\n",
       "<tr><td class=\"label\">Human</td><td><span class=\"A_dna\">.</span><span class=\"T_dna\">.</span><span class=\"G_dna\">.</span><span class=\"T_dna\">.</span><span class=\"C_dna\">.</span><span class=\"G_dna\">.</span><span class=\"G_dna\">.</span><span class=\"A_dna\">.</span><span class=\"G_dna\">.</span><span class=\"C_dna\">C</span><span class=\"C_dna\">C</span><span class=\"C_dna\">C</span><span class=\"G_dna\">G</span><span class=\"G_dna\">G</span><span class=\"G_dna\">G</span><span class=\"G_dna\">.</span><span class=\"G_dna\">.</span><span class=\"C_dna\">.</span><span class=\"G_dna\">.</span><span class=\"G_dna\">.</span><span class=\"C_dna\">.</span><span class=\"G_dna\">.</span><span class=\"G_dna\">.</span><span class=\"C_dna\">.</span><span class=\"G_dna\">.</span><span class=\"G_dna\">.</span><span class=\"C_dna\">.</span><span class=\"G_dna\">.</span><span class=\"A_dna\">.</span><span class=\"G_dna\">.</span><span class=\"G_dna\">.</span><span class=\"A_dna\">.</span><span class=\"C_dna\">.</span><span class=\"G_dna\">.</span><span class=\"G_dna\">.</span><span class=\"C_dna\">.</span><span class=\"T_dna\">.</span><span class=\"C_dna\">.</span><span class=\"G_dna\">.</span><span class=\"G_dna\">G</span><span class=\"C_dna\">.</span><span class=\"C_dna\">C</span><span class=\"G_dna\">.</span><span class=\"G_dna\">.</span><span class=\"A_dna\">A</span><span class=\"T_dna\">T</span><span class=\"T_dna\">.</span><span class=\"G_dna\">.</span><span class=\"G_dna\">.</span><span class=\"A_dna\">.</span><span class=\"A_dna\">A</span><span class=\"G_dna\">.</span><span class=\"T_dna\">.</span><span class=\"G_dna\">.</span><span class=\"T_dna\">.</span><span class=\"C_dna\">.</span><span class=\"G_dna\">.</span><span class=\"G_dna\">.</span><span class=\"C_dna\">.</span><span class=\"C_dna\">C</span></td></tr>\n",
       "<tr><td class=\"label\">Mouse</td><td><span class=\"A_dna\">.</span><span class=\"T_dna\">.</span><span class=\"G_dna\">.</span><span class=\"T_dna\">.</span><span class=\"C_dna\">.</span><span class=\"G_dna\">.</span><span class=\"G_dna\">.</span><span class=\"A_dna\">.</span><span class=\"G_dna\">.</span><span class=\"C_dna\">C</span><span class=\"C_dna\">C</span><span class=\"G_dna\">G</span><span class=\"ambig_dna\">.</span><span class=\"ambig_dna\">.</span><span class=\"ambig_dna\">.</span><span class=\"ambig_dna\">-</span><span class=\"ambig_dna\">-</span><span class=\"ambig_dna\">-</span><span class=\"G_dna\">.</span><span class=\"G_dna\">.</span><span class=\"C_dna\">.</span><span class=\"G_dna\">.</span><span class=\"G_dna\">.</span><span class=\"C_dna\">.</span><span class=\"G_dna\">.</span><span class=\"G_dna\">.</span><span class=\"C_dna\">.</span><span class=\"G_dna\">.</span><span class=\"A_dna\">.</span><span class=\"G_dna\">.</span><span class=\"G_dna\">.</span><span class=\"A_dna\">.</span><span class=\"C_dna\">.</span><span class=\"G_dna\">.</span><span class=\"G_dna\">.</span><span class=\"C_dna\">.</span><span class=\"T_dna\">.</span><span class=\"C_dna\">.</span><span class=\"G_dna\">.</span><span class=\"G_dna\">G</span><span class=\"C_dna\">.</span><span class=\"C_dna\">C</span><span class=\"G_dna\">.</span><span class=\"G_dna\">.</span><span class=\"C_dna\">.</span><span class=\"C_dna\">.</span><span class=\"T_dna\">.</span><span class=\"G_dna\">.</span><span class=\"G_dna\">.</span><span class=\"A_dna\">.</span><span class=\"G_dna\">.</span><span class=\"G_dna\">.</span><span class=\"T_dna\">.</span><span class=\"G_dna\">.</span><span class=\"T_dna\">.</span><span class=\"C_dna\">.</span><span class=\"G_dna\">.</span><span class=\"G_dna\">.</span><span class=\"C_dna\">.</span><span class=\"G_dna\">.</span></td></tr>\n",
       "<tr><td class=\"label\">Opossum</td><td><span class=\"ambig_dna\">-</span><span class=\"ambig_dna\">-</span><span class=\"ambig_dna\">-</span><span class=\"ambig_dna\">-</span><span class=\"ambig_dna\">-</span><span class=\"ambig_dna\">-</span><span class=\"ambig_dna\">-</span><span class=\"ambig_dna\">-</span><span class=\"ambig_dna\">-</span><span class=\"ambig_dna\">.</span><span class=\"ambig_dna\">.</span><span class=\"ambig_dna\">.</span><span class=\"ambig_dna\">.</span><span class=\"ambig_dna\">.</span><span class=\"ambig_dna\">.</span><span class=\"ambig_dna\">-</span><span class=\"ambig_dna\">-</span><span class=\"ambig_dna\">-</span><span class=\"ambig_dna\">-</span><span class=\"ambig_dna\">-</span><span class=\"ambig_dna\">-</span><span class=\"ambig_dna\">-</span><span class=\"ambig_dna\">-</span><span class=\"ambig_dna\">-</span><span class=\"ambig_dna\">-</span><span class=\"ambig_dna\">-</span><span class=\"ambig_dna\">-</span><span class=\"ambig_dna\">-</span><span class=\"ambig_dna\">-</span><span class=\"ambig_dna\">-</span><span class=\"ambig_dna\">-</span><span class=\"ambig_dna\">-</span><span class=\"ambig_dna\">-</span><span class=\"ambig_dna\">-</span><span class=\"ambig_dna\">-</span><span class=\"ambig_dna\">-</span><span class=\"ambig_dna\">-</span><span class=\"ambig_dna\">-</span><span class=\"ambig_dna\">-</span><span class=\"ambig_dna\">-</span><span class=\"ambig_dna\">-</span><span class=\"ambig_dna\">-</span><span class=\"ambig_dna\">-</span><span class=\"ambig_dna\">-</span><span class=\"ambig_dna\">-</span><span class=\"ambig_dna\">-</span><span class=\"ambig_dna\">-</span><span class=\"ambig_dna\">-</span><span class=\"ambig_dna\">-</span><span class=\"ambig_dna\">-</span><span class=\"ambig_dna\">-</span><span class=\"ambig_dna\">-</span><span class=\"ambig_dna\">-</span><span class=\"ambig_dna\">-</span><span class=\"ambig_dna\">-</span><span class=\"ambig_dna\">-</span><span class=\"ambig_dna\">-</span><span class=\"ambig_dna\">-</span><span class=\"ambig_dna\">-</span><span class=\"ambig_dna\">-</span></td></tr>\n",
       "</table>\n",
       "<p><i>5 x 13962 (truncated to 5 x 60) dna alignment</i></p>\n",
       "</div>"
      ],
      "text/plain": [
       "5 x 13962 dna alignment: Dog[ATGTCGGAGCC...], Human[ATGTCGGAGCC...], Mouse[ATGTCGGAGCC...], ..."
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aln"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "663fab3c",
   "metadata": {},
   "source": [
    "### All at once\n",
    "First run `triple-threat` all the way through. Run time is not fantastic for five taxa, but it also fits non-stationary models to all edges, and is expected to scale well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cfc09993",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 4406 positions\n",
      "Looking for cherries\n",
      "Step: 1, initial loss: 2.0050997734069824\n",
      "Step: 101, initial loss: 1.699263334274292\n",
      "Step: 201, initial loss: 1.1660088300704956\n",
      "Step: 301, initial loss: 0.4601401388645172\n",
      "Step: 401, initial loss: 0.34876924753189087\n",
      "Step: 501, initial loss: 0.2980298101902008\n",
      "Step: 601, initial loss: 0.27511167526245117\n",
      "Step: 701, initial loss: 0.265436589717865\n",
      "Step: 801, initial loss: 0.25224578380584717\n",
      "Step: 901, initial loss: 0.2409302294254303\n",
      "Step: 1001, initial loss: 0.23519524931907654\n",
      "Step: 1101, initial loss: 0.2128434181213379\n",
      "Step: 1201, initial loss: 0.20457565784454346\n",
      "Step: 1301, initial loss: 0.18996067345142365\n",
      "Step: 1401, initial loss: 0.17771275341510773\n",
      "Step: 1501, initial loss: 0.16422908008098602\n",
      "Step: 1601, initial loss: 0.14813873171806335\n",
      "Step: 1701, initial loss: 0.1435757577419281\n",
      "Step: 1801, initial loss: 0.14247237145900726\n",
      "Step: 1901, initial loss: 0.1379510760307312\n",
      "Step: 2001, initial loss: 0.1373562216758728\n",
      "Step: 2101, initial loss: 0.1365962028503418\n",
      "Step: 2201, initial loss: 0.134865865111351\n",
      "Step: 2301, initial loss: 0.13441069424152374\n",
      "Step: 2401, initial loss: 0.13129062950611115\n",
      "Step: 2501, initial loss: 0.11225546151399612\n",
      "Step: 2601, initial loss: 0.107187420129776\n",
      "Step: 2701, initial loss: 0.10193818062543869\n",
      "Step: 2801, initial loss: 0.10140010714530945\n",
      "Step: 2901, initial loss: 0.1009143516421318\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function pfor.<locals>.f at 0x7fab55468790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Dog, Human: -1.3787476122379303\n",
      "Mouse, Dog: -1.8279661238193512\n",
      "Mouse, Human: -1.8752942234277725\n",
      "Opossum, Platypus: -2.0682355761528015\n",
      "Mouse, Platypus: -46.92740046977997\n",
      "Dog, Platypus: -48.15459620952606\n",
      "Human, Platypus: -51.565237045288086\n",
      "Opossum, Human: -52.27160048484802\n",
      "Mouse, Opossum: -80.75851970911026\n",
      "Opossum, Dog: -99.10046768188477\n",
      "Fitting cherries\n",
      "Step: 1, initial loss: 0.7025399208068848\n",
      "Step: 101, initial loss: 0.6109020113945007\n",
      "Step: 201, initial loss: 0.4033234715461731\n",
      "Step: 301, initial loss: 0.17115342617034912\n",
      "Step: 401, initial loss: 0.13761840760707855\n",
      "Step: 501, initial loss: 0.10374010354280472\n",
      "Step: 601, initial loss: 0.0920722559094429\n",
      "Step: 701, initial loss: 0.08904032409191132\n",
      "Step: 801, initial loss: 0.08812067657709122\n",
      "Step: 901, initial loss: 0.08751534670591354\n",
      "Step: 1001, initial loss: 0.08682620525360107\n",
      "Step: 1101, initial loss: 0.07311718165874481\n",
      "Step: 1201, initial loss: 0.07192473113536835\n",
      "Step: 1301, initial loss: 0.07171831279993057\n",
      "Step: 1401, initial loss: 0.07160042971372604\n",
      "Step: 1501, initial loss: 0.07152481377124786\n",
      "Step: 1601, initial loss: 0.07146907597780228\n",
      "Step: 1701, initial loss: 0.07142515480518341\n",
      "Step: 1801, initial loss: 0.0713864341378212\n",
      "Step: 1901, initial loss: 0.07133619487285614\n",
      "Step: 2001, initial loss: 0.0698082223534584\n",
      "Step: 2101, initial loss: 0.06962953507900238\n",
      "Step: 2201, initial loss: 0.061795733869075775\n",
      "Step: 2301, initial loss: 0.05613899230957031\n",
      "Step: 2401, initial loss: 0.056019775569438934\n",
      "Step: 2501, initial loss: 0.055781587958335876\n",
      "Step: 2601, initial loss: 0.054782044142484665\n",
      "Step: 2701, initial loss: 0.054408442229032516\n",
      "Step: 2801, initial loss: 0.05371236056089401\n",
      "Step: 2901, initial loss: 0.05335705354809761\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function pfor.<locals>.f at 0x7fab540ad940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Mouse;\n",
      "Opossum;\n",
      "Platypus;\n",
      "(Dog,Human)Dog-Human;\n",
      "Merging cherries\n",
      "WARNING:tensorflow:Using a while_loop for converting ResourceGather\n",
      "Step: 1, initial loss: 0.18745288252830505\n",
      "Step: 101, initial loss: 0.05638427659869194\n",
      "Step: 201, initial loss: 0.0167072843760252\n",
      "Step: 301, initial loss: 0.01195750292390585\n",
      "Step: 401, initial loss: 0.010876157321035862\n",
      "Step: 501, initial loss: 0.010257057845592499\n",
      "Step: 601, initial loss: 0.009714684449136257\n",
      "Step: 701, initial loss: 0.009140599519014359\n",
      "Step: 801, initial loss: 0.008488872088491917\n",
      "Step: 901, initial loss: 0.007733214646577835\n",
      "Step: 1001, initial loss: 0.006858966778963804\n",
      "Step: 1101, initial loss: 0.005867938511073589\n",
      "Step: 1201, initial loss: 0.004791035316884518\n",
      "Step: 1301, initial loss: 0.0037013289984315634\n",
      "Step: 1401, initial loss: 0.0027081184089183807\n",
      "Step: 1501, initial loss: 0.0019128855783492327\n",
      "Step: 1601, initial loss: 0.0013548322021961212\n",
      "Step: 1701, initial loss: 0.0010043643414974213\n",
      "Step: 1801, initial loss: 0.0008013200713321567\n",
      "Step: 1901, initial loss: 0.0006893235258758068\n",
      "Step: 2001, initial loss: 0.0006286556599661708\n",
      "Step: 2101, initial loss: 0.0005954722873866558\n",
      "Step: 2201, initial loss: 0.0005767987458966672\n",
      "Step: 2301, initial loss: 0.0005658995360136032\n",
      "Step: 2401, initial loss: 0.0005592872621491551\n",
      "Step: 2501, initial loss: 0.0005551168578676879\n",
      "Step: 2601, initial loss: 0.0005524184089154005\n",
      "Step: 2701, initial loss: 0.0005506289307959378\n",
      "Step: 2801, initial loss: 0.0005494138458743691\n",
      "Step: 2901, initial loss: 0.0005485827568918467\n",
      "WARNING:tensorflow:7 out of the last 13 calls to <function merge_cherries.<locals>.transform at 0x7fab51951dc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Looking for cherries\n",
      "Step: 1, initial loss: 0.7358664274215698\n",
      "Step: 101, initial loss: 0.6172635555267334\n",
      "Step: 201, initial loss: 0.4568202495574951\n",
      "Step: 301, initial loss: 0.1582885980606079\n",
      "Step: 401, initial loss: 0.12087483704090118\n",
      "Step: 501, initial loss: 0.11376410722732544\n",
      "Step: 601, initial loss: 0.11070217192173004\n",
      "Step: 701, initial loss: 0.10928888618946075\n",
      "Step: 801, initial loss: 0.1026516929268837\n",
      "Step: 901, initial loss: 0.10008262097835541\n",
      "Step: 1001, initial loss: 0.09618633985519409\n",
      "Step: 1101, initial loss: 0.0908675268292427\n",
      "Step: 1201, initial loss: 0.08135951310396194\n",
      "Step: 1301, initial loss: 0.07269314676523209\n",
      "Step: 1401, initial loss: 0.07051241397857666\n",
      "Step: 1501, initial loss: 0.06564699113368988\n",
      "Step: 1601, initial loss: 0.055150821805000305\n",
      "Step: 1701, initial loss: 0.0528298020362854\n",
      "Step: 1801, initial loss: 0.0500798374414444\n",
      "Step: 1901, initial loss: 0.049725379794836044\n",
      "Step: 2001, initial loss: 0.0493718683719635\n",
      "Step: 2101, initial loss: 0.04914388805627823\n",
      "Step: 2201, initial loss: 0.04901011288166046\n",
      "Step: 2301, initial loss: 0.042578209191560745\n",
      "Step: 2401, initial loss: 0.03754809498786926\n",
      "Step: 2501, initial loss: 0.033945392817258835\n",
      "Step: 2601, initial loss: 0.0337844081223011\n",
      "Step: 2701, initial loss: 0.03301198408007622\n",
      "Step: 2801, initial loss: 0.03276693448424339\n",
      "Step: 2901, initial loss: 0.03261024132370949\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:11 out of the last 11 calls to <function pfor.<locals>.f at 0x7fab525f1040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Mouse, Dog-Human: -0.7382480502128601\n",
      "Opossum, Platypus: -1.7115052938461304\n",
      "Opossum, Dog-Human: -2.054489850997925\n",
      "Mouse, Opossum: -37.92973393201828\n",
      "Mouse, Platypus: -41.13019585609436\n",
      "Dog-Human, Platypus: -42.67369222640991\n",
      "Fitting cherries\n",
      "Step: 1, initial loss: 0.37203001976013184\n",
      "Step: 101, initial loss: 0.31469833850860596\n",
      "Step: 201, initial loss: 0.21630287170410156\n",
      "Step: 301, initial loss: 0.07224678993225098\n",
      "Step: 401, initial loss: 0.05269111320376396\n",
      "Step: 501, initial loss: 0.04841533303260803\n",
      "Step: 601, initial loss: 0.046584099531173706\n",
      "Step: 701, initial loss: 0.04116344824433327\n",
      "Step: 801, initial loss: 0.034670811146497726\n",
      "Step: 901, initial loss: 0.031730230897665024\n",
      "Step: 1001, initial loss: 0.031393181532621384\n",
      "Step: 1101, initial loss: 0.031220776960253716\n",
      "Step: 1201, initial loss: 0.031097780913114548\n",
      "Step: 1301, initial loss: 0.03100006654858589\n",
      "Step: 1401, initial loss: 0.03091934323310852\n",
      "Step: 1501, initial loss: 0.030855314806103706\n",
      "Step: 1601, initial loss: 0.030808500945568085\n",
      "Step: 1701, initial loss: 0.03077154979109764\n",
      "Step: 1801, initial loss: 0.030736086890101433\n",
      "Step: 1901, initial loss: 0.030551910400390625\n",
      "Step: 2001, initial loss: 0.02759747952222824\n",
      "Step: 2101, initial loss: 0.027270710095763206\n",
      "Step: 2201, initial loss: 0.027012554928660393\n",
      "Step: 2301, initial loss: 0.026822423562407494\n",
      "Step: 2401, initial loss: 0.026711245998740196\n",
      "Step: 2501, initial loss: 0.026111872866749763\n",
      "Step: 2601, initial loss: 0.018612459301948547\n",
      "Step: 2701, initial loss: 0.018300827592611313\n",
      "Step: 2801, initial loss: 0.01797943189740181\n",
      "Step: 2901, initial loss: 0.01641177386045456\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function pfor.<locals>.f at 0x7fab53ae05e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Opossum;\n",
      "Platypus;\n",
      "(Mouse,(Dog,Human)Dog-Human)Mouse-Dog-Human;\n",
      "Merging cherries\n",
      "WARNING:tensorflow:Using a while_loop for converting ResourceGather\n",
      "Step: 1, initial loss: 0.061430931091308594\n",
      "Step: 101, initial loss: 0.017970632761716843\n",
      "Step: 201, initial loss: 0.006022403948009014\n",
      "Step: 301, initial loss: 0.004624098539352417\n",
      "Step: 401, initial loss: 0.0042762975208461285\n",
      "Step: 501, initial loss: 0.004054209217429161\n",
      "Step: 601, initial loss: 0.003843307262286544\n",
      "Step: 701, initial loss: 0.003610059153288603\n",
      "Step: 801, initial loss: 0.003338275011628866\n",
      "Step: 901, initial loss: 0.00301724998280406\n",
      "Step: 1001, initial loss: 0.002640743739902973\n",
      "Step: 1101, initial loss: 0.0022106273099780083\n",
      "Step: 1201, initial loss: 0.0017438177019357681\n",
      "Step: 1301, initial loss: 0.0012786558363586664\n",
      "Step: 1401, initial loss: 0.0008701011538505554\n",
      "Step: 1501, initial loss: 0.0005648512742482126\n",
      "Step: 1601, initial loss: 0.0003727070870809257\n",
      "Step: 1701, initial loss: 0.00026775215519592166\n",
      "Step: 1801, initial loss: 0.00021489898790605366\n",
      "Step: 1901, initial loss: 0.0001887622056528926\n",
      "Step: 2001, initial loss: 0.00017552751523908228\n",
      "Step: 2101, initial loss: 0.00016855579451657832\n",
      "Step: 2201, initial loss: 0.00016475752636324614\n",
      "Step: 2301, initial loss: 0.00016264006262645125\n",
      "Step: 2401, initial loss: 0.00016143216635100543\n",
      "Step: 2501, initial loss: 0.0001607394515303895\n",
      "Step: 2601, initial loss: 0.0001603478449396789\n",
      "Step: 2701, initial loss: 0.0001601208932697773\n",
      "Step: 2801, initial loss: 0.00015999109018594027\n",
      "Step: 2901, initial loss: 0.00015992035332601517\n",
      "WARNING:tensorflow:6 out of the last 12 calls to <function merge_cherries.<locals>.transform at 0x7fab51cc0dc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Looking for cherries\n",
      "Step: 1, initial loss: 0.18279902637004852\n",
      "Step: 101, initial loss: 0.1504203975200653\n",
      "Step: 201, initial loss: 0.11397983133792877\n",
      "Step: 301, initial loss: 0.059335798025131226\n",
      "Step: 401, initial loss: 0.034593645483255386\n",
      "Step: 501, initial loss: 0.03264879435300827\n",
      "Step: 601, initial loss: 0.032306551933288574\n",
      "Step: 701, initial loss: 0.03217306360602379\n",
      "Step: 801, initial loss: 0.0312686525285244\n",
      "Step: 901, initial loss: 0.027727292850613594\n",
      "Step: 1001, initial loss: 0.027534300461411476\n",
      "Step: 1101, initial loss: 0.027400275692343712\n",
      "Step: 1201, initial loss: 0.027296174317598343\n",
      "Step: 1301, initial loss: 0.02691362053155899\n",
      "Step: 1401, initial loss: 0.022642649710178375\n",
      "Step: 1501, initial loss: 0.022028902545571327\n",
      "Step: 1601, initial loss: 0.021894626319408417\n",
      "Step: 1701, initial loss: 0.019259147346019745\n",
      "Step: 1801, initial loss: 0.012274042703211308\n",
      "Step: 1901, initial loss: 0.01186454389244318\n",
      "Step: 2001, initial loss: 0.011737351305782795\n",
      "Step: 2101, initial loss: 0.011705388315021992\n",
      "Step: 2201, initial loss: 0.011690190993249416\n",
      "Step: 2301, initial loss: 0.011680979281663895\n",
      "Step: 2401, initial loss: 0.011674666777253151\n",
      "Step: 2501, initial loss: 0.011670209467411041\n",
      "Step: 2601, initial loss: 0.011666295118629932\n",
      "Step: 2701, initial loss: 0.011663337238132954\n",
      "Step: 2801, initial loss: 0.011660370044410229\n",
      "Step: 2901, initial loss: 0.011658554896712303\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function pfor.<locals>.f at 0x7fab524fa160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Opossum, Mouse-Dog-Human: -0.5547000169754028\n",
      "Opossum, Platypus: -0.853890061378479\n",
      "Mouse-Dog-Human, Platypus: -45.21558380126953\n",
      "Fitting cherries\n",
      "Step: 1, initial loss: 0.18089018762111664\n",
      "Step: 101, initial loss: 0.15032894909381866\n",
      "Step: 201, initial loss: 0.11287202686071396\n",
      "Step: 301, initial loss: 0.041573017835617065\n",
      "Step: 401, initial loss: 0.03349200636148453\n",
      "Step: 501, initial loss: 0.03253093361854553\n",
      "Step: 601, initial loss: 0.032249435782432556\n",
      "Step: 701, initial loss: 0.03212882950901985\n",
      "Step: 801, initial loss: 0.03143859654664993\n",
      "Step: 901, initial loss: 0.027658093720674515\n",
      "Step: 1001, initial loss: 0.027464015409350395\n",
      "Step: 1101, initial loss: 0.027303321287035942\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 1201, initial loss: 0.022450005635619164\n",
      "Step: 1301, initial loss: 0.016299208626151085\n",
      "Step: 1401, initial loss: 0.012470549903810024\n",
      "Step: 1501, initial loss: 0.011936123482882977\n",
      "Step: 1601, initial loss: 0.011813578195869923\n",
      "Step: 1701, initial loss: 0.01175751257687807\n",
      "Step: 1801, initial loss: 0.011725084856152534\n",
      "Step: 1901, initial loss: 0.0117051862180233\n",
      "Step: 2001, initial loss: 0.011692282743752003\n",
      "Step: 2101, initial loss: 0.011683222837746143\n",
      "Step: 2201, initial loss: 0.011676255613565445\n",
      "Step: 2301, initial loss: 0.011670678853988647\n",
      "Step: 2401, initial loss: 0.011665689758956432\n",
      "Step: 2501, initial loss: 0.011660991236567497\n",
      "Step: 2601, initial loss: 0.011653145775198936\n",
      "Step: 2701, initial loss: 0.011438918299973011\n",
      "Step: 2801, initial loss: 0.010594790801405907\n",
      "Step: 2901, initial loss: 0.010543818585574627\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function pfor.<locals>.f at 0x7fab517fe1f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Platypus;\n",
      "(Opossum,(Mouse,(Dog,Human)Dog-Human)Mouse-Dog-Human)Opossum-Mouse-Dog-Human;\n",
      "CPU times: user 10min 8s, sys: 1min 26s, total: 11min 35s\n",
      "Wall time: 4min 22s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "triples = get_triples(aln, verbose=True)\n",
    "tree = triple_threat(triples, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "25c46792",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          /-Platypus\n",
      "-Platypus-Opossum-Mouse-Dog-Human\n",
      "         |          /-Opossum\n",
      "          \\Opossum-Mouse-Dog-Human\n",
      "                   |          /-Mouse\n",
      "                    \\Mouse-Dog-Human\n",
      "                             |          /-Dog\n",
      "                              \\Dog-Human\n",
      "                                        \\-Human\n"
     ]
    }
   ],
   "source": [
    "print(tree.ascii_art())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a39380",
   "metadata": {},
   "source": [
    "## Example 2\n",
    "### A single iteration\n",
    "Now run through a single iteration of the algorithm.\n",
    "#### Fit triples\n",
    "This step fits rooted, strand-symmetric, continuous-time models to every taxon triple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b171e885",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 4406 positions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-02 14:15:54.529725: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-09-02 14:15:54.551956: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2599990000 Hz\n",
      "2021-09-02 14:15:54.552824: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55b8b2e3ac20 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-09-02 14:15:54.552856: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2021-09-02 14:15:54.631071: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-09-02 14:15:54.631417: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55b8b2e3ba30 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2021-09-02 14:15:54.631428: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 2080 with Max-Q Design, Compute Capability 7.5\n",
      "2021-09-02 14:15:54.631565: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-09-02 14:15:54.631873: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA GeForce RTX 2080 with Max-Q Design computeCapability: 7.5\n",
      "coreClock: 1.095GHz coreCount: 46 deviceMemorySize: 7.79GiB deviceMemoryBandwidth: 357.69GiB/s\n",
      "2021-09-02 14:15:54.631895: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
      "2021-09-02 14:15:54.631911: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
      "2021-09-02 14:15:54.631921: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\n",
      "2021-09-02 14:15:54.631931: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\n",
      "2021-09-02 14:15:54.631940: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\n",
      "2021-09-02 14:15:54.631949: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\n",
      "2021-09-02 14:15:54.631958: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n",
      "2021-09-02 14:15:54.631999: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-09-02 14:15:54.632259: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-09-02 14:15:54.632487: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\n",
      "2021-09-02 14:15:54.632505: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
      "2021-09-02 14:15:54.935275: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-09-02 14:15:54.935295: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0 \n",
      "2021-09-02 14:15:54.935300: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N \n",
      "2021-09-02 14:15:54.935455: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-09-02 14:15:54.935852: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-09-02 14:15:54.936094: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 6738 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 2080 with Max-Q Design, pci bus id: 0000:01:00.0, compute capability: 7.5)\n",
      "2021-09-02 14:16:07.019712: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
      "2021-09-02 14:16:07.161125: I tensorflow/core/kernels/cuda_solvers.cc:180] Creating CudaSolver handles for stream 0x55b8b31a6da0\n",
      "2021-09-02 14:16:07.161277: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\n",
      "2021-09-02 14:16:07.319451: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 1, initial loss: 2.0066494941711426\n",
      "Step: 101, initial loss: 1.6990165710449219\n",
      "Step: 201, initial loss: 1.1723039150238037\n",
      "Step: 301, initial loss: 0.4476985037326813\n",
      "Step: 401, initial loss: 0.3442932963371277\n",
      "Step: 501, initial loss: 0.32133156061172485\n",
      "Step: 601, initial loss: 0.3021972179412842\n",
      "Step: 701, initial loss: 0.2701646387577057\n",
      "Step: 801, initial loss: 0.25689423084259033\n",
      "Step: 901, initial loss: 0.24404454231262207\n",
      "Step: 1001, initial loss: 0.23771673440933228\n",
      "Step: 1101, initial loss: 0.21686285734176636\n",
      "Step: 1201, initial loss: 0.20941677689552307\n",
      "Step: 1301, initial loss: 0.18028579652309418\n",
      "Step: 1401, initial loss: 0.16758763790130615\n",
      "Step: 1501, initial loss: 0.16270193457603455\n",
      "Step: 1601, initial loss: 0.15450730919837952\n",
      "Step: 1701, initial loss: 0.15144827961921692\n",
      "Step: 1801, initial loss: 0.14939221739768982\n",
      "Step: 1901, initial loss: 0.14767670631408691\n",
      "Step: 2001, initial loss: 0.14716917276382446\n",
      "Step: 2101, initial loss: 0.14671730995178223\n",
      "Step: 2201, initial loss: 0.14574730396270752\n",
      "Step: 2301, initial loss: 0.13235780596733093\n",
      "Step: 2401, initial loss: 0.12810632586479187\n",
      "Step: 2501, initial loss: 0.12015929818153381\n",
      "Step: 2601, initial loss: 0.11844368278980255\n",
      "Step: 2701, initial loss: 0.1136450320482254\n",
      "Step: 2801, initial loss: 0.11117039620876312\n",
      "Step: 2901, initial loss: 0.1106981709599495\n",
      "CPU times: user 1min 59s, sys: 15.3 s, total: 2min 14s\n",
      "Wall time: 1min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "triples = get_triples(aln, verbose=True)\n",
    "losses, fits = fit_triples(triples, cherries_share_matrices=False, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b326c574",
   "metadata": {},
   "source": [
    "### Find the most probably cherry\n",
    "This step finds the pair of taxa that are most likely to be a cherries using model selection calculations, then simultaneously fits that cherry across all of the triples of which it is a part to estimate its rate matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "407c1108",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dog, Human: -1.0707451105117798\n",
      "Mouse, Dog: -1.8164032697677612\n",
      "Mouse, Human: -1.8881000876426697\n",
      "Opossum, Platypus: -2.5792858600616455\n",
      "Mouse, Platypus: -46.93198621273041\n",
      "Opossum, Human: -51.83248162269592\n",
      "Opossum, Dog: -54.830931663513184\n",
      "Mouse, Opossum: -80.58363389968872\n",
      "Human, Platypus: -91.7210224866867\n",
      "Dog, Platypus: -97.26261615753174\n",
      "Step: 1, initial loss: 0.7077893018722534\n",
      "Step: 101, initial loss: 0.6105999946594238\n",
      "Step: 201, initial loss: 0.39786848425865173\n",
      "Step: 301, initial loss: 0.1679067462682724\n",
      "Step: 401, initial loss: 0.13688445091247559\n",
      "Step: 501, initial loss: 0.13185706734657288\n",
      "Step: 601, initial loss: 0.11637300997972488\n",
      "Step: 701, initial loss: 0.09264581650495529\n",
      "Step: 801, initial loss: 0.09011288732290268\n",
      "Step: 901, initial loss: 0.08946087956428528\n",
      "Step: 1001, initial loss: 0.08910869061946869\n",
      "Step: 1101, initial loss: 0.08884220570325851\n",
      "Step: 1201, initial loss: 0.08711621910333633\n",
      "Step: 1301, initial loss: 0.07376112043857574\n",
      "Step: 1401, initial loss: 0.059351857751607895\n",
      "Step: 1501, initial loss: 0.05852563679218292\n",
      "Step: 1601, initial loss: 0.05836432799696922\n",
      "Step: 1701, initial loss: 0.058278970420360565\n",
      "Step: 1801, initial loss: 0.058221325278282166\n",
      "Step: 1901, initial loss: 0.0581778809428215\n",
      "Step: 2001, initial loss: 0.05814357101917267\n",
      "Step: 2101, initial loss: 0.058111730962991714\n",
      "Step: 2201, initial loss: 0.057875242084264755\n",
      "Step: 2301, initial loss: 0.05646670237183571\n",
      "Step: 2401, initial loss: 0.056268688291311264\n",
      "Step: 2501, initial loss: 0.05567306652665138\n",
      "Step: 2601, initial loss: 0.054254766553640366\n",
      "Step: 2701, initial loss: 0.053658708930015564\n",
      "Step: 2801, initial loss: 0.05316299945116043\n",
      "Step: 2901, initial loss: 0.052912335842847824\n"
     ]
    }
   ],
   "source": [
    "cherry_names = get_cherries(triples, losses, verbose=True)\n",
    "triples_for_cherry = [t for t in triples if set(cherry_names) < set(t[0])]\n",
    "_, fits = fit_triples(triples_for_cherry, cherries_share_matrices=True, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28fe77c7",
   "metadata": {},
   "source": [
    "This step extracts the simultaneously fitted transition probability matrices for the cherry taxa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "592eaaf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cherry_Ps = get_Ps(cherry_names, triples_for_cherry, fits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f166f744",
   "metadata": {},
   "source": [
    "Test a single agglomeration step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "50ce671b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "forest = {}\n",
    "cherries = cherry_names, cherry_Ps\n",
    "update_tree(forest, cherries)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51683252",
   "metadata": {},
   "source": [
    "These were the cherry taxa and their corresponding transition probability matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e2aadcfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['Dog', 'Human'],\n",
       " (array([[0.70033926, 0.0410389 , 0.23727772, 0.02134408],\n",
       "         [0.00668178, 0.90446866, 0.02488895, 0.06396052],\n",
       "         [0.06396053, 0.02488895, 0.9044687 , 0.00668178],\n",
       "         [0.02134408, 0.23727769, 0.0410389 , 0.70033926]], dtype=float32),\n",
       "  array([[0.7839454 , 0.02744941, 0.1780567 , 0.01054858],\n",
       "         [0.00591483, 0.9303335 , 0.00940431, 0.05434741],\n",
       "         [0.0543474 , 0.00940431, 0.93033355, 0.00591483],\n",
       "         [0.01054858, 0.1780567 , 0.02744941, 0.7839453 ]], dtype=float32)))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cherries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "81ca9937",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Dog-Human': Tree(\"(Dog,Human)Dog-Human;\")}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c703fab2",
   "metadata": {},
   "source": [
    "These were the data that were fitted simultaneously to find the above rate matrics for Dog and Human."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "510fee3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('Dog', 'Human', 'Mouse'),\n",
       "  array([[[ 283,   33,  137,   19],\n",
       "          [  18,   22,    6,    2],\n",
       "          [  44,   16,  113,    7],\n",
       "          [   4,    5,    4,   18]],\n",
       "  \n",
       "         [[  22,   13,   15,    5],\n",
       "          [  14,  841,   27,  111],\n",
       "          [  11,   16,   32,    5],\n",
       "          [  11,  122,   14,  127]],\n",
       "  \n",
       "         [[  76,   14,  100,    9],\n",
       "          [   4,   22,   13,    9],\n",
       "          [ 121,   40, 1019,   21],\n",
       "          [   0,   13,   12,   11]],\n",
       "  \n",
       "         [[   9,    5,    3,    3],\n",
       "          [   7,  108,   12,   76],\n",
       "          [   4,    4,    7,   10],\n",
       "          [  23,  172,   36,  326]]], dtype=int32)],\n",
       " [('Dog', 'Human', 'Opossum'),\n",
       "  array([[[338,  19,  71,  44],\n",
       "          [ 21,   4,   6,  17],\n",
       "          [ 89,  10,  58,  23],\n",
       "          [ 12,   1,   3,  15]],\n",
       "  \n",
       "         [[ 29,   6,   4,  16],\n",
       "          [ 89, 476,  39, 389],\n",
       "          [ 20,  10,  17,  17],\n",
       "          [ 19,  62,   8, 185]],\n",
       "  \n",
       "         [[113,  10,  55,  21],\n",
       "          [ 13,  17,   3,  15],\n",
       "          [358,  26, 737,  80],\n",
       "          [  7,   5,   4,  20]],\n",
       "  \n",
       "         [[  6,   2,   2,  10],\n",
       "          [ 18,  48,   1, 136],\n",
       "          [ 10,   5,   2,   8],\n",
       "          [ 32,  72,   8, 445]]], dtype=int32)],\n",
       " [('Dog', 'Human', 'Platypus'),\n",
       "  array([[[310,  22,  98,  42],\n",
       "          [ 20,   3,   3,  22],\n",
       "          [ 86,  11,  62,  21],\n",
       "          [  9,   2,   1,  19]],\n",
       "  \n",
       "         [[ 26,   8,   6,  15],\n",
       "          [ 83, 498,  34, 378],\n",
       "          [ 18,   8,  20,  18],\n",
       "          [ 19,  71,  14, 170]],\n",
       "  \n",
       "         [[102,  12,  62,  23],\n",
       "          [  8,  12,   9,  19],\n",
       "          [335,  36, 741,  89],\n",
       "          [  6,   6,   2,  22]],\n",
       "  \n",
       "         [[  6,   5,   1,   8],\n",
       "          [ 23,  55,   6, 119],\n",
       "          [ 10,   2,   5,   8],\n",
       "          [ 45, 100,  24, 388]]], dtype=int32)]]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "triples_for_cherry"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "640b9834",
   "metadata": {},
   "source": [
    "### Merge the cherries\n",
    "Merge the cherries by fitting the triples between the unmerged taxa and the new merged node, using the probability matrices that we fitted above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1a71b25c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting ResourceGather\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ben/miniconda3/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:431: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 1, initial loss: 0.18694207072257996\n",
      "Step: 101, initial loss: 0.05630214512348175\n",
      "Step: 201, initial loss: 0.016560954973101616\n",
      "Step: 301, initial loss: 0.011870048940181732\n",
      "Step: 401, initial loss: 0.010795547626912594\n",
      "Step: 501, initial loss: 0.010174106806516647\n",
      "Step: 601, initial loss: 0.009626062586903572\n",
      "Step: 701, initial loss: 0.009043915197253227\n",
      "Step: 801, initial loss: 0.008381888270378113\n",
      "Step: 901, initial loss: 0.007614144589751959\n",
      "Step: 1001, initial loss: 0.006727422121912241\n",
      "Step: 1101, initial loss: 0.005726528353989124\n",
      "Step: 1201, initial loss: 0.004647366236895323\n",
      "Step: 1301, initial loss: 0.0035685193724930286\n",
      "Step: 1401, initial loss: 0.0026003215461969376\n",
      "Step: 1501, initial loss: 0.001836904906667769\n",
      "Step: 1601, initial loss: 0.001307002967223525\n",
      "Step: 1701, initial loss: 0.0009760017856024206\n",
      "Step: 1801, initial loss: 0.0007846312946639955\n",
      "Step: 1901, initial loss: 0.0006791851483285427\n",
      "Step: 2001, initial loss: 0.0006221724906936288\n",
      "Step: 2101, initial loss: 0.0005911450716666877\n",
      "Step: 2201, initial loss: 0.0005738224717788398\n",
      "Step: 2301, initial loss: 0.0005638061556965113\n",
      "Step: 2401, initial loss: 0.0005577937699854374\n",
      "Step: 2501, initial loss: 0.0005540661513805389\n",
      "Step: 2601, initial loss: 0.0005516769597306848\n",
      "Step: 2701, initial loss: 0.0005501082050614059\n",
      "Step: 2801, initial loss: 0.0005490577314049006\n",
      "Step: 2901, initial loss: 0.000548340380191803\n",
      "CPU times: user 9.44 s, sys: 696 ms, total: 10.1 s\n",
      "Wall time: 5.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "triples = merge_cherries(triples, cherries, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d113b6",
   "metadata": {},
   "source": [
    "At the end of the first iteration, the triples now consist of unmerged taxa and the newly created merged node (called \"Dog-Human\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ad536c15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('Mouse', 'Opossum', 'Platypus'),\n",
       "  array([[[276,  15,  80,  24],\n",
       "          [ 11,  12,   3,   9],\n",
       "          [ 50,   3,  62,   3],\n",
       "          [ 25,  12,   8,  58]],\n",
       "  \n",
       "         [[ 90,  37,  20,  30],\n",
       "          [ 37, 353,  18, 159],\n",
       "          [ 10,  12,  24,   9],\n",
       "          [ 28, 181,  12, 426]],\n",
       "  \n",
       "         [[315,  15, 166,  25],\n",
       "          [  9,  15,   9,  18],\n",
       "          [150,  17, 631,  23],\n",
       "          [ 22,  25,  18,  92]],\n",
       "  \n",
       "         [[ 37,  11,  12,  21],\n",
       "          [ 10,  56,   4,  50],\n",
       "          [  4,   6,  10,   4],\n",
       "          [ 32,  81,  11, 410]]], dtype=int32)),\n",
       " (['Mouse', 'Opossum', 'Dog-Human'],\n",
       "  array([[[271.39813  ,  17.798874 ,  94.73732  ,  10.987216 ],\n",
       "          [ 11.867694 ,  14.324279 ,   5.5005774,   2.9197848],\n",
       "          [ 44.02035  ,   2.1981473,  70.13179  ,   2.260109 ],\n",
       "          [ 42.59225  ,  15.920035 ,  19.829195 ,  24.439869 ]],\n",
       "  \n",
       "         [[ 35.510742 ,  90.71925  ,  31.583857 ,  19.548342 ],\n",
       "          [ 10.520011 , 467.30704  ,  19.237043 ,  71.135506 ],\n",
       "          [  6.0260153,  31.02173  ,  11.523313 ,   6.3489623],\n",
       "          [ 18.38188  , 406.13574  ,  19.829115 , 203.96733  ]],\n",
       "  \n",
       "         [[149.40486  ,  17.282177 , 343.92648  ,   9.980027 ],\n",
       "          [  5.500331 ,  14.004349 ,  22.977062 ,   8.512557 ],\n",
       "          [ 83.01503  ,  16.660467 , 717.939    ,   4.2738013],\n",
       "          [ 19.95581  ,  22.557274 ,  75.63024  ,  39.057526 ]],\n",
       "  \n",
       "         [[ 17.542515 ,  21.554192 ,  14.463563 ,  27.53557  ],\n",
       "          [  7.508059 ,  55.117573 ,   6.347764 ,  51.05418  ],\n",
       "          [  2.2385025,   7.771741 ,   9.028474 ,   4.610844 ],\n",
       "          [ 13.114571 , 137.20515  ,  16.53933  , 363.96964  ]]],\n",
       "        dtype=float32)),\n",
       " (['Mouse', 'Platypus', 'Dog-Human'],\n",
       "  array([[[244.55408  ,  19.410547 ,  90.5219   ,   7.44652  ],\n",
       "          [ 17.384947 ,   8.978753 ,  10.038111 ,   5.316996 ],\n",
       "          [ 73.02174  ,   2.937072 ,  70.61612  ,   4.614198 ],\n",
       "          [ 35.114758 ,  17.557983 ,  19.514198 ,  22.081232 ]],\n",
       "  \n",
       "         [[ 33.992317 ,  86.81815  ,  21.291546 ,  23.084835 ],\n",
       "          [  8.808935 , 480.76108  ,  10.623568 ,  83.626465 ],\n",
       "          [  6.352248 ,  37.122936 ,  22.08118  ,   8.1559   ],\n",
       "          [ 20.199112 , 391.42996  ,  27.043657 , 185.99011  ]],\n",
       "  \n",
       "         [[144.53226  ,  16.795376 , 327.1989   ,   8.978882 ],\n",
       "          [  9.523163 ,  18.038984 ,  35.59914  ,   9.034886 ],\n",
       "          [ 81.0759   ,  13.7991   , 721.5567   ,   9.035161 ],\n",
       "          [ 22.73303  ,  22.53276  ,  77.25835  ,  34.999832 ]],\n",
       "  \n",
       "         [[ 12.536779 ,  17.06316  ,  12.003269 ,  41.650124 ],\n",
       "          [  6.509071 ,  70.673096 ,   4.2748737,  72.62745  ],\n",
       "          [  5.0271826,   6.025018 ,   9.523503 ,  15.7747345],\n",
       "          [ 16.308434 , 128.06465  ,  20.422192 , 318.33313  ]]],\n",
       "        dtype=float32)),\n",
       " (['Opossum', 'Platypus', 'Dog-Human'],\n",
       "  array([[[344.73233  ,  63.646248 , 275.62613  ,  35.409355 ],\n",
       "          [ 16.531227 ,  36.581604 ,  17.533867 ,   7.502042 ],\n",
       "          [ 84.04683  ,  19.018124 , 165.38245  ,   9.510094 ],\n",
       "          [ 28.526752 ,  29.462294 ,  26.328974 ,  14.867604 ]],\n",
       "  \n",
       "         [[ 12.028906 ,  36.0839   ,   8.144392 ,  10.222806 ],\n",
       "          [ 10.417622 , 352.82245  ,  14.175642 ,  58.531456 ],\n",
       "          [  3.507108 ,  14.525781 ,  11.516732 ,   4.496459 ],\n",
       "          [  9.51012  , 147.28885  ,  19.487753 ,  59.93081  ]],\n",
       "  \n",
       "         [[ 56.611843 ,   9.51012  , 146.82086  ,   1.7336072],\n",
       "          [  4.0318456,  17.78992  ,  12.87581  ,   2.8924718],\n",
       "          [ 69.5738   ,  18.373278 , 631.9282   ,   7.957662 ],\n",
       "          [  4.913407 ,  11.860373 ,  16.531256 ,   4.9139833]],\n",
       "  \n",
       "         [[ 22.028559 ,  30.484612 ,  19.946249 ,  33.94626  ],\n",
       "          [ 10.980961 , 170.32344  ,  15.911888 , 101.67652  ],\n",
       "          [  8.506681 ,   9.974266 ,  14.033433 ,  16.531393 ],\n",
       "          [ 52.352074 , 371.63846  ,  82.093575 , 479.85648  ]]],\n",
       "        dtype=float32))]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "triples"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

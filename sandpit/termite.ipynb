{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95afc4bd",
   "metadata": {},
   "source": [
    "# `TERMITE`\n",
    "sTrand symmEtric tRiple MIncuTsupErtree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f71f1501",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "from cogent3 import load_aligned_seqs, PhyloNode\n",
    "import numpy as np\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88a792d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-13 06:30:14.947332: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "tfd = tfp.distributions\n",
    "tfb = tfp.bijectors\n",
    "\n",
    "tf.executing_eagerly()  # need to check whether this is the default for tensorflow > 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bccbca69",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-13 06:30:15.998917: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1\n",
      "2021-09-13 06:30:16.072549: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-09-13 06:30:16.072853: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA GeForce RTX 2080 with Max-Q Design computeCapability: 7.5\n",
      "coreClock: 1.095GHz coreCount: 46 deviceMemorySize: 7.79GiB deviceMemoryBandwidth: 357.69GiB/s\n",
      "2021-09-13 06:30:16.072871: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
      "2021-09-13 06:30:16.074331: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
      "2021-09-13 06:30:16.075550: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\n",
      "2021-09-13 06:30:16.075764: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\n",
      "2021-09-13 06:30:16.077201: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\n",
      "2021-09-13 06:30:16.077869: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\n",
      "2021-09-13 06:30:16.080657: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n",
      "2021-09-13 06:30:16.080775: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-09-13 06:30:16.081151: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-09-13 06:30:16.081426: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\n"
     ]
    }
   ],
   "source": [
    "# this stops tensorflow from snaffling all of the GPU\n",
    "# thanks https://stackoverflow.com/questions/34199233/how-to-prevent-tensorflow-from-allocating-the-totality-of-a-gpu-memory\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "  tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e4daac3",
   "metadata": {},
   "source": [
    "## Data import\n",
    "Reads an alignments and creates a list of 4 x 4 x 4 joint frequencies tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "81060425",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_triples(aln, nuc_order='ACGT', codon_position=None, verbose=False):\n",
    "    if codon_position:\n",
    "        aln = aln[codon_position - 1::3]\n",
    "    aln = aln.no_degenerates()\n",
    "    if verbose:\n",
    "        print(f'Got {len(aln)} positions')\n",
    "    assert len(aln) <= np.iinfo(np.int32).max\n",
    "    triples = []\n",
    "    nuc_map = {n:i for i, n in enumerate(nuc_order)}\n",
    "    for triple in combinations(range(aln.num_seqs), 3):\n",
    "        F = np.zeros([4, 4, 4], dtype=np.int32)\n",
    "        subaln = aln.get_sub_alignment(seqs=triple)\n",
    "        for a, b, c in subaln:\n",
    "            F[nuc_map[a], nuc_map[b], nuc_map[c]] += 1\n",
    "        triples.append([tuple(subaln.names), F])\n",
    "    return triples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da7937f2",
   "metadata": {},
   "source": [
    "## Triple fitting functions\n",
    "Collection of functions for concurrent fitting of many triples on CPUs and GPUs. Model is rooted, continuous-time, and strand-symmetric.\n",
    "\n",
    "Also some functions for using Akaike-ish weights to build Semple and Steel-ish graphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b5ddd765",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function()\n",
    "def transform_P_matrix(params):\n",
    "    params = tf.exp(params)\n",
    "    Q0 = tf.concat([[-tf.reduce_sum(params[0])], params[0]],\n",
    "                   axis=0)\n",
    "    Q1 = tf.concat([[params[1,0]], [-tf.reduce_sum(params[1])], params[1,1:]],\n",
    "                   axis=0)\n",
    "    Q = tf.concat([[Q0], [Q1], [Q1[::-1]], [Q0[::-1]]], axis=0)\n",
    "    return tf.linalg.expm(Q)\n",
    "\n",
    "@tf.function()\n",
    "def transform(params):\n",
    "    pi = tfb.SoftmaxCentered()(params[0])\n",
    "    Pa = transform_P_matrix(params[1:3])\n",
    "    Pm = transform_P_matrix(params[3:5])\n",
    "    Pb = transform_P_matrix(params[5:7])\n",
    "    Pc = transform_P_matrix(params[7:9])\n",
    "    return pi, Pa, Pm, Pb, Pc\n",
    "    \n",
    "@tf.function()\n",
    "def _loss(params_data):\n",
    "    params, data = params_data\n",
    "    pi, Pa, Pm, Pb, Pc = transform(params)\n",
    "    J = tf.einsum('i,ij,ik,ku,kv', pi, Pa, Pm, Pb, Pc)\n",
    "    loss = tf.reduce_sum(tf.keras.losses.KLDivergence()(J, data))\n",
    "    return loss\n",
    "    \n",
    "@tf.function()\n",
    "def loss(params, data):\n",
    "    # could do better managing the variance in the shared matrix case here\n",
    "    return tf.reduce_sum(tf.vectorized_map(_loss, (params, data)))\n",
    "\n",
    "@tf.function()\n",
    "def training_step(parameters, data, optimizer, unscrambler):\n",
    "    with tf.GradientTape() as tape:\n",
    "        unscrambled = _unscramble(parameters, unscrambler)\n",
    "        loss_value = loss(unscrambled, data)\n",
    "    gradients = tape.gradient(loss_value, parameters)\n",
    "    return loss_value, gradients\n",
    "\n",
    "# thanks https://github.com/mlgxmez/thelongrun_notebooks/blob/master/MLE_tutorial.ipynb\n",
    "def mle_fit(data, loss, parameters, optimizer, unscrambler, steps=500, verbose=False):\n",
    "    for i in range(steps):\n",
    "        loss_value, gradients = training_step(parameters, data, optimizer, unscrambler)\n",
    "        optimizer.apply_gradients([(gradients, parameters)])\n",
    "        \n",
    "        if i % 100 == 0:\n",
    "            if verbose:\n",
    "                iter_info = f\"Step: {optimizer.iterations.numpy()}, initial loss: {loss_value.numpy()}\"\n",
    "                print(iter_info)\n",
    "\n",
    "@tf.function()\n",
    "def _unscramble(parameters, unscramble):\n",
    "    unscrambled = []\n",
    "    for t1 in unscramble:\n",
    "        unscrambled.append(tf.stack([parameters[i] for i in t1]))\n",
    "    return tf.stack(unscrambled)\n",
    "\n",
    "def fit_triples(triples, learning_rate=0.01, cherries_share_matrices=True, steps=3000, verbose=False):\n",
    "    K = 0\n",
    "    cherry_loc = {}\n",
    "    unscrambler = []\n",
    "    data = []\n",
    "    for names, F in triples:\n",
    "        J = (F/F.sum()).astype(np.float32)\n",
    "        for ix in [[0, 1, 2], [1, 2, 0], [2, 0, 1]]:\n",
    "            t1 = list(range(K, K+5)) # for pi and two Ps\n",
    "            K += 5\n",
    "            cherry = [names[ix[1]], names[ix[2]]]\n",
    "            frozen_cherry = frozenset(cherry)\n",
    "            if not cherries_share_matrices or frozen_cherry not in cherry_loc:\n",
    "                new_loc = {cherry[0]: [K,K+1], cherry[1]: [K+2,K+3]}\n",
    "                K += 4\n",
    "                cherry_loc[frozen_cherry] = new_loc\n",
    "            t1.extend(cherry_loc[frozen_cherry][cherry[0]]) # for the first cherry\n",
    "            t1.extend(cherry_loc[frozen_cherry][cherry[1]]) # for the second cherry\n",
    "            unscrambler.append(t1)\n",
    "        \n",
    "            data.append(J.transpose(ix))\n",
    "\n",
    "    normal_initializer = tf.random_normal_initializer()\n",
    "    parameters = tf.Variable(normal_initializer(shape=[K, 3], dtype=tf.float32), name='params')\n",
    "    data = tf.stack(data)\n",
    "    \n",
    "    if verbose:\n",
    "        print(f'Fitting {data.shape[0]} triples')\n",
    "    optimizer = tf.optimizers.Adam(learning_rate=learning_rate)\n",
    "    mle_fit(data, loss, parameters, optimizer, unscrambler, steps=steps, verbose=verbose)\n",
    "    \n",
    "    parameters = _unscramble(parameters, unscrambler)\n",
    "    losses = tf.vectorized_map(_loss, (parameters, data)).numpy()\n",
    "    losses = [losses[i:i+3] for i in range(0, len(losses), 3)]\n",
    "    fits = [[p.numpy() for p in transform(params)] for params in parameters]\n",
    "    fits = [fits[i:i+3] for i in range(0, len(fits), 3)]\n",
    "    return losses, fits\n",
    "\n",
    "def cherry_weights(ls, N):\n",
    "    ls = N*ls\n",
    "    delta = ls - ls.min()\n",
    "    weights = np.exp(-delta)\n",
    "    return weights/weights.sum()\n",
    "\n",
    "def get_edges(triples, losses):\n",
    "    edges = Counter()\n",
    "    for losses, (names, F) in zip(losses, triples):\n",
    "        weights = cherry_weights(losses, F.sum())\n",
    "        for name, weight in zip(names, weights):\n",
    "            edges[frozenset(names) - {name}] += weight\n",
    "    return edges\n",
    "\n",
    "def get_Ps(cherry_names, triples, fits):\n",
    "    Ps = {}\n",
    "    ixes = [[0, 1, 2], [1, 2, 0], [2, 0, 1]]\n",
    "    for (names, _), triple_fit in zip(triples, fits):\n",
    "        if set(cherry_names) < set(names):\n",
    "            for name, ix, fit in zip(names, ixes, triple_fit):\n",
    "                if name not in cherry_names:\n",
    "                    if names[ix[1]] == cherry_names[0]:\n",
    "                        return fit[-2], fit[-1]\n",
    "                    return fit[-1], fit[-2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd83a62a",
   "metadata": {},
   "source": [
    "## Tree building algorithm\n",
    "Where the magic happens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e2c4030",
   "metadata": {},
   "outputs": [],
   "source": [
    "def termite(triples, learning_rate=0.01, steps=3000, verbose=False):\n",
    "    losses, _ = fit_triples(triples, cherries_share_matrices=False,\n",
    "                               learning_rate=learning_rate, steps=steps, verbose=verbose)\n",
    "    tree = termite_tree(triples, losses, verbose=verbose)\n",
    "    return tree\n",
    "    \n",
    "def termite_tree(triples, losses, verbose=False):\n",
    "    edges = get_edges(triples, losses)\n",
    "    if verbose:\n",
    "        print('Graph:')\n",
    "        for edge, weight in edges.items():\n",
    "            print(edge, weight)\n",
    "    G = nx.Graph()\n",
    "    for edge, weight in edges.items():\n",
    "        G.add_edge(*edge, weight=weight)\n",
    "    cut_value, partition = nx.stoer_wagner(G)\n",
    "    if verbose:\n",
    "        print(f'Cut value: {cut_value}, Partition:\\n{partition}')\n",
    "    assert len(partition) == 2, 'polytomy detected. bailing'\n",
    "    this_node = PhyloNode()\n",
    "    for part in partition:\n",
    "        if len(part) <= 1:\n",
    "            this_node.append(PhyloNode(part.pop()))\n",
    "            continue\n",
    "        elif len(part) == 2:\n",
    "            child = PhyloNode()\n",
    "            for grandchild in part:\n",
    "                child.append(PhyloNode(grandchild))\n",
    "            this_node.append(child)\n",
    "            continue\n",
    "    \n",
    "        part = set(part)\n",
    "        part_losses = []\n",
    "        part_triples = []\n",
    "        for losses, (names, F) in zip(losses, triples):\n",
    "            if set(names) <= part:\n",
    "                part_losses.append(losses)\n",
    "                part_triples.append((names, F))\n",
    "        this_node.append(termite_tree(part_triples, part_losses, verbose=verbose))\n",
    "    return this_node"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b347257",
   "metadata": {},
   "source": [
    "# Some examples\n",
    "## Example 1\n",
    "Fit a rooted phylogeny of 5 mammals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d05c519d",
   "metadata": {},
   "outputs": [],
   "source": [
    "aln = load_aligned_seqs('/home/ben/Data/pentads/ENSG00000197102.fa.gz', moltype=\"dna\")\n",
    "# aln = load_aligned_seqs('/home/ben/Data/pentads/ENSG00000131018.fa.gz', moltype=\"dna\")\n",
    "# aln = load_aligned_seqs('/home/ben/Data/pentads/ENSG00000179869.fa.gz', moltype=\"dna\")\n",
    "# aln = load_aligned_seqs('brca1.fasta', moltype='dna')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "097ad3f8",
   "metadata": {},
   "source": [
    "### All at once\n",
    "First run `termite` all the way through."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "949531eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 4406 positions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-13 06:30:22.894771: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-09-13 06:30:22.916349: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2599990000 Hz\n",
      "2021-09-13 06:30:22.916984: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55a8b985c290 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-09-13 06:30:22.916996: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2021-09-13 06:30:22.975985: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-09-13 06:30:22.976331: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55a8ba591650 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2021-09-13 06:30:22.976342: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 2080 with Max-Q Design, Compute Capability 7.5\n",
      "2021-09-13 06:30:22.976501: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-09-13 06:30:22.976762: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA GeForce RTX 2080 with Max-Q Design computeCapability: 7.5\n",
      "coreClock: 1.095GHz coreCount: 46 deviceMemorySize: 7.79GiB deviceMemoryBandwidth: 357.69GiB/s\n",
      "2021-09-13 06:30:22.976785: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
      "2021-09-13 06:30:22.976804: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
      "2021-09-13 06:30:22.976815: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\n",
      "2021-09-13 06:30:22.976825: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\n",
      "2021-09-13 06:30:22.976835: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\n",
      "2021-09-13 06:30:22.976845: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\n",
      "2021-09-13 06:30:22.976857: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n",
      "2021-09-13 06:30:22.976898: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-09-13 06:30:22.977175: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-09-13 06:30:22.977417: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\n",
      "2021-09-13 06:30:22.977441: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
      "2021-09-13 06:30:23.310234: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-09-13 06:30:23.310260: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0 \n",
      "2021-09-13 06:30:23.310265: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N \n",
      "2021-09-13 06:30:23.310454: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-09-13 06:30:23.310795: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-09-13 06:30:23.311053: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 6953 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 2080 with Max-Q Design, pci bus id: 0000:01:00.0, compute capability: 7.5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 30 triples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-13 06:30:37.314545: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
      "2021-09-13 06:30:37.478705: I tensorflow/core/kernels/cuda_solvers.cc:180] Creating CudaSolver handles for stream 0x55a8b593be90\n",
      "2021-09-13 06:30:37.478853: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\n",
      "2021-09-13 06:30:37.672809: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 1, initial loss: 2.002349615097046\n",
      "Step: 101, initial loss: 1.6990163326263428\n",
      "Step: 201, initial loss: 1.1770401000976562\n",
      "Step: 301, initial loss: 0.4651837646961212\n",
      "Step: 401, initial loss: 0.33783480525016785\n",
      "Step: 501, initial loss: 0.3070788085460663\n",
      "Step: 601, initial loss: 0.29280954599380493\n",
      "Step: 701, initial loss: 0.2708946168422699\n",
      "Step: 801, initial loss: 0.253675639629364\n",
      "Step: 901, initial loss: 0.22664757072925568\n",
      "Step: 1001, initial loss: 0.21593135595321655\n",
      "Step: 1101, initial loss: 0.19900184869766235\n",
      "Step: 1201, initial loss: 0.19339296221733093\n",
      "Step: 1301, initial loss: 0.18176187574863434\n",
      "Step: 1401, initial loss: 0.16928890347480774\n",
      "Step: 1501, initial loss: 0.1574772596359253\n",
      "Step: 1601, initial loss: 0.15164227783679962\n",
      "Step: 1701, initial loss: 0.145457461476326\n",
      "Step: 1801, initial loss: 0.14200682938098907\n",
      "Step: 1901, initial loss: 0.14094436168670654\n",
      "Step: 2001, initial loss: 0.13856738805770874\n",
      "Step: 2101, initial loss: 0.1372535675764084\n",
      "Step: 2201, initial loss: 0.13654357194900513\n",
      "Step: 2301, initial loss: 0.13537058234214783\n",
      "Step: 2401, initial loss: 0.12294908612966537\n",
      "Step: 2501, initial loss: 0.11864644289016724\n",
      "Step: 2601, initial loss: 0.11038625985383987\n",
      "Step: 2701, initial loss: 0.10925909876823425\n",
      "Step: 2801, initial loss: 0.10308356583118439\n",
      "Step: 2901, initial loss: 0.10258906334638596\n",
      "Graph:\n",
      "frozenset({'Mouse', 'Human'}) 1.7130411863327026\n",
      "frozenset({'Mouse', 'Dog'}) 1.731557011604309\n",
      "frozenset({'Dog', 'Human'}) 2.3464691936969757\n",
      "frozenset({'Human', 'Opossum'}) 0.5798106044530869\n",
      "frozenset({'Dog', 'Opossum'}) 0.8386458903551102\n",
      "frozenset({'Platypus', 'Human'}) 0.519862100481987\n",
      "frozenset({'Platypus', 'Dog'}) 0.18305404484272003\n",
      "frozenset({'Mouse', 'Opossum'}) 0.5764179825782817\n",
      "frozenset({'Mouse', 'Platypus'}) 0.3980519473552704\n",
      "frozenset({'Platypus', 'Opossum'}) 1.11309015750885\n",
      "Cut value: 2.2140582501888275, Partition:\n",
      "(['Platypus'], ['Mouse', 'Dog', 'Opossum', 'Human'])\n",
      "Graph:\n",
      "frozenset({'Mouse', 'Human'}) 1.0879722237586975\n",
      "frozenset({'Mouse', 'Dog'}) 1.1150239706039429\n",
      "frozenset({'Dog', 'Human'}) 1.3464691936969757\n",
      "frozenset({'Human', 'Opossum'}) 0.21941007673740387\n",
      "frozenset({'Dog', 'Opossum'}) 0.23112459480762482\n",
      "frozenset({'Mouse', 'Opossum'}) 4.122036805326362e-15\n",
      "Cut value: 0.4505346715450328, Partition:\n",
      "(['Opossum'], ['Mouse', 'Human', 'Dog'])\n",
      "Graph:\n",
      "frozenset({'Mouse', 'Human'}) 0.3073822855949402\n",
      "frozenset({'Mouse', 'Dog'}) 0.3461484909057617\n",
      "frozenset({'Dog', 'Human'}) 0.3464691936969757\n",
      "Cut value: 0.6535307765007019, Partition:\n",
      "(['Dog', 'Human'], ['Mouse'])\n",
      "          /-Platypus\n",
      "         |\n",
      "---------|          /-Opossum\n",
      "         |         |\n",
      "          \\--------|                    /-Dog\n",
      "                   |          /--------|\n",
      "                    \\--------|          \\-Human\n",
      "                             |\n",
      "                              \\-Mouse\n",
      "CPU times: user 2min 12s, sys: 15.7 s, total: 2min 28s\n",
      "Wall time: 1min 10s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "triples = get_triples(aln, codon_position=3, verbose=True)\n",
    "tree = termite(triples, verbose=True)\n",
    "print(tree.ascii_art())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c248a02",
   "metadata": {},
   "source": [
    "## Example 2\n",
    "### A single iteration\n",
    "Now run through a single iteration of the algorithm.\n",
    "#### Fit triples\n",
    "Fits rooted, strand-symmetric, continuous-time models to every taxon triple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "10c1aaf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 30 triples\n",
      "Step: 1, initial loss: 2.0117835998535156\n",
      "Step: 101, initial loss: 1.698805809020996\n",
      "Step: 201, initial loss: 1.186188817024231\n",
      "Step: 301, initial loss: 0.459677129983902\n",
      "Step: 401, initial loss: 0.3385312855243683\n",
      "Step: 501, initial loss: 0.3154182434082031\n",
      "Step: 601, initial loss: 0.31015241146087646\n",
      "Step: 701, initial loss: 0.3008975386619568\n",
      "Step: 801, initial loss: 0.27459800243377686\n",
      "Step: 901, initial loss: 0.26621389389038086\n",
      "Step: 1001, initial loss: 0.2488139271736145\n",
      "Step: 1101, initial loss: 0.24297833442687988\n",
      "Step: 1201, initial loss: 0.2217521369457245\n",
      "Step: 1301, initial loss: 0.20997193455696106\n",
      "Step: 1401, initial loss: 0.18395183980464935\n",
      "Step: 1501, initial loss: 0.17843468487262726\n",
      "Step: 1601, initial loss: 0.16511203348636627\n",
      "Step: 1701, initial loss: 0.1607339084148407\n",
      "Step: 1801, initial loss: 0.15662065148353577\n",
      "Step: 1901, initial loss: 0.1522778570652008\n",
      "Step: 2001, initial loss: 0.14635497331619263\n",
      "Step: 2101, initial loss: 0.1456945240497589\n",
      "Step: 2201, initial loss: 0.14416304230690002\n",
      "Step: 2301, initial loss: 0.13562902808189392\n",
      "Step: 2401, initial loss: 0.12621334195137024\n",
      "Step: 2501, initial loss: 0.11750602722167969\n",
      "Step: 2601, initial loss: 0.11064998805522919\n",
      "Step: 2701, initial loss: 0.10997021943330765\n",
      "Step: 2801, initial loss: 0.10971561819314957\n",
      "Step: 2901, initial loss: 0.10878226906061172\n"
     ]
    }
   ],
   "source": [
    "losses, fits = fit_triples(triples, cherries_share_matrices=False, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d94ad1",
   "metadata": {},
   "source": [
    "#### Create $S_\\mathcal{T}\\left/E^\\text{max}_\\mathcal{T}\\right.$\n",
    "Creates the edges in Semple and Steel's $S_\\mathcal{T}\\left/E^\\text{max}_\\mathcal{T}\\right.$ graph, at least as I understand it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a361870c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({frozenset({'Human', 'Mouse'}): 1.7177821099758148,\n",
       "         frozenset({'Dog', 'Mouse'}): 1.866870939731598,\n",
       "         frozenset({'Dog', 'Human'}): 2.342536687850952,\n",
       "         frozenset({'Human', 'Opossum'}): 0.5797104686498642,\n",
       "         frozenset({'Dog', 'Opossum'}): 0.840646892786026,\n",
       "         frozenset({'Human', 'Platypus'}): 0.5245423316955566,\n",
       "         frozenset({'Dog', 'Platypus'}): 0.23943248391151428,\n",
       "         frozenset({'Mouse', 'Opossum'}): 0.5786677002906842,\n",
       "         frozenset({'Mouse', 'Platypus'}): 0.19638927280904406,\n",
       "         frozenset({'Opossum', 'Platypus'}): 1.1134211421012878})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edges = get_edges(triples, losses)\n",
    "edges"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd238ae0",
   "metadata": {},
   "source": [
    "#### Find the root by partitioning on the minimum cut\n",
    "Perform the minimum cut to partition our tip set into two, one either side of the root."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8d52ae56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cut value: 2.073785230517403, Partition:\n",
      "(['Platypus'], ['Mouse', 'Dog', 'Opossum', 'Human'])\n"
     ]
    }
   ],
   "source": [
    "G = nx.Graph()\n",
    "for edge, weight in edges.items():\n",
    "    G.add_edge(*edge, weight=weight)\n",
    "cut_value, partition = nx.stoer_wagner(G)\n",
    "print(f'Cut value: {cut_value}, Partition:\\n{partition}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62db9549",
   "metadata": {},
   "source": [
    "The rest is left as an exercise for the reader (or just look in `termite` above) - the algorithm continues recursively."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
